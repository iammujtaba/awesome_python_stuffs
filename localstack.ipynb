{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3122e14e-5301-47ac-9cad-f3212c7d8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12efaf7e-a317-4fcc-979a-c0bd5f31c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below 2 line will redirect all the request to local aws i.e. localstack not aws\n",
    "from localstack_client.patch import enable_local_endpoints\n",
    "enable_local_endpoints()\n",
    "\n",
    "# This is disable localstack and request will go to aws endpoint not localstack\n",
    "# from localstack_client.patch import disable_local_endpoints()\n",
    "# disable_local_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27aebb70-53ad-4e45-bfe6-5723f36f40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws configure set aws_access_key_id \"dummy\" --profile test-profile\n",
    "# aws configure set aws_secret_access_key \"dummy\" --profile test-profile\n",
    "# aws configure set region \"ap-south-1\" --profile test-profile\n",
    "# aws configure set output \"table\" --profile test-profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38337253-2ee8-4f7c-b2bc-37f86fd752d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boto3.session.Session(profile_name='test-profile')   # this is used when we have multiple profiles like dev prod local etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aefc629c-6ffe-4c2b-94c0-aa8f7ca11f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "response = client.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "611496c8-6edb-4348-9757-8399a9cd5b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3651b924-9a6b-43d6-afd6-14f3c894643b',\n",
       "  'HostId': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/xml',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'access-control-allow-methods': 'HEAD,GET,PUT,POST,DELETE,OPTIONS,PATCH',\n",
       "   'access-control-allow-headers': 'authorization,cache-control,content-length,content-md5,content-type,etag,location,x-amz-acl,x-amz-content-sha256,x-amz-date,x-amz-request-id,x-amz-security-token,x-amz-tagging,x-amz-target,x-amz-user-agent,x-amz-version-id,x-amzn-requestid,x-localstack-target,amz-sdk-invocation-id,amz-sdk-request',\n",
       "   'access-control-expose-headers': 'etag,x-amz-version-id',\n",
       "   'content-length': '222',\n",
       "   'x-amz-request-id': '3651b924-9a6b-43d6-afd6-14f3c894643b',\n",
       "   'x-amz-id-2': 's9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234=',\n",
       "   'connection': 'close',\n",
       "   'date': 'Tue, 17 Oct 2023 11:11:46 GMT',\n",
       "   'server': 'hypercorn-h11'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [],\n",
       " 'Owner': {'DisplayName': 'webfile',\n",
       "  'ID': '75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a767da-7a77-4173-87af-0a8e96fe5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqs = boto3.client('sqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0e2ad0c-24d6-4614-bb93-4874623e1828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QueueUrls': ['http://localhost:4566/000000000000/dummy-queue'],\n",
       " 'ResponseMetadata': {'RequestId': '3ecdf933-20e1-4b3c-a594-72e8bb314704',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'text/xml',\n",
       "   'content-length': '331',\n",
       "   'connection': 'close',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'access-control-allow-methods': 'HEAD,GET,PUT,POST,DELETE,OPTIONS,PATCH',\n",
       "   'access-control-allow-headers': 'authorization,cache-control,content-length,content-md5,content-type,etag,location,x-amz-acl,x-amz-content-sha256,x-amz-date,x-amz-request-id,x-amz-security-token,x-amz-tagging,x-amz-target,x-amz-user-agent,x-amz-version-id,x-amzn-requestid,x-localstack-target,amz-sdk-invocation-id,amz-sdk-request',\n",
       "   'access-control-expose-headers': 'etag,x-amz-version-id',\n",
       "   'date': 'Tue, 17 Oct 2023 11:11:46 GMT',\n",
       "   'server': 'hypercorn-h11'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqs.list_queues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "410620f1-52b8-44d7-9d35-7a270aa07998",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_url = 'http://localhost:4566/000000000000/dummy-queue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4345f04c-b4b9-4eff-9f2c-600854a95242",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sqs.send_message(\n",
    "    QueueUrl=queue_url,\n",
    "    DelaySeconds=1,\n",
    "    MessageBody=('Test Message')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ced25f4-f171-4963-b1e0-d29c1c9aace3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MD5OfMessageBody': 'd1d4180b7e411c4be86b00fb2ee103eb',\n",
       " 'MessageId': '43f9646c-4fe9-418b-867e-4ac16afce869',\n",
       " 'ResponseMetadata': {'RequestId': 'b6a1786c-65be-4eb4-b5e1-4f30e646cfa3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'text/xml',\n",
       "   'content-length': '396',\n",
       "   'connection': 'close',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'access-control-allow-methods': 'HEAD,GET,PUT,POST,DELETE,OPTIONS,PATCH',\n",
       "   'access-control-allow-headers': 'authorization,cache-control,content-length,content-md5,content-type,etag,location,x-amz-acl,x-amz-content-sha256,x-amz-date,x-amz-request-id,x-amz-security-token,x-amz-tagging,x-amz-target,x-amz-user-agent,x-amz-version-id,x-amzn-requestid,x-localstack-target,amz-sdk-invocation-id,amz-sdk-request',\n",
       "   'access-control-expose-headers': 'etag,x-amz-version-id',\n",
       "   'date': 'Tue, 17 Oct 2023 11:11:47 GMT',\n",
       "   'server': 'hypercorn-h11'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e8b2e-1ba3-468e-acf2-95fde7a0f49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91fb0195-a460-4a1a-9b4e-98a9b98dee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sqs.receive_message(\n",
    "    QueueUrl=queue_url,\n",
    "    AttributeNames=['All'],\n",
    "    MaxNumberOfMessages=10,\n",
    "    VisibilityTimeout=0,\n",
    "    WaitTimeSeconds=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cd6008e-bf7b-41d0-80bb-8650596ed9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Type\": \"Notification\", \"MessageId\": \"ad15cf17-7150-4fcd-b88e-9d83f0ac7748\", \"TopicArn\": \"arn:aws:sns:ap-south-1:000000000000:order-creation-events\", \"Message\": \"Hello World\", \"Timestamp\": \"2023-10-15T18:37:49.139Z\", \"SignatureVersion\": \"1\", \"Signature\": \"EXAMPLEpH+..\", \"SigningCertURL\": \"https://sns.ap-south-1.amazonaws.com/SimpleNotificationService-0000000000000000000000.pem\", \"UnsubscribeURL\": \"http://localhost:4566/?Action=Unsubscribe&SubscriptionArn=arn:aws:sns:ap-south-1:000000000000:order-creation-events:cf909ed5-f49f-423f-8d13-efbbedaadf16\"}\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n",
      "Test Message\n"
     ]
    }
   ],
   "source": [
    "messages = response['Messages']\n",
    "for message in messages:\n",
    "    print(message['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663a136-1091-4537-8ea7-b9dfc6aa9785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ddb1b05-c638-445c-b4d8-b3d9a45d196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating kinesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "990a55e2-4fa6-452f-9507-d3531d26d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kinesis_client = boto3.client('kinesis')\n",
    "stream_name='pyspark-kinesis'\n",
    "# kinesis_client.create_stream(\n",
    "#         StreamName=stream_name,\n",
    "#         ShardCount=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd23e379-3834-47bc-8b79-fd1bd1792ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "messages = [\n",
    "    {'message_type': 'message1', 'count': 2},\n",
    "    {'message_type': 'message2', 'count': 1},\n",
    "    {'message_type': 'message1', 'count': 2},\n",
    "    {'message_type': 'message3', 'count': 3},\n",
    "    {'message_type': 'message1', 'count': 5}\n",
    "]\n",
    "for message in messages:\n",
    "    kinesis_client.put_record(\n",
    "        StreamName=stream_name,\n",
    "        Data=json.dumps(message),\n",
    "        PartitionKey='part_key')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38c50eba-3cfb-4a0d-838a-5998839211c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_records(Records):\n",
    "    print(Records)\n",
    "    \n",
    "def main():    \n",
    "    try:\n",
    "        kinesis_client = boto3.client('kinesis')\n",
    "\n",
    "        #------------------\n",
    "        # Get the shard ID.\n",
    "        #------------------\n",
    "        response = kinesis_client.describe_stream(StreamName=stream_name)\n",
    "        shard_id = response['StreamDescription']['Shards'][0]['ShardId']\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        # Get the shard iterator.\n",
    "        # ShardIteratorType=AT_SEQUENCE_NUMBER|AFTER_SEQUENCE_NUMBER|TRIM_HORIZON|LATEST|AT_TIMESTAMP\n",
    "        #---------------------------------------------------------------------------------------------\n",
    "        response = kinesis_client.get_shard_iterator(\n",
    "            StreamName=stream_name,\n",
    "            ShardId=shard_id,\n",
    "            ShardIteratorType='TRIM_HORIZON'\n",
    "        )\n",
    "        shard_iterator = response['ShardIterator']\n",
    "\n",
    "        #-----------------------------------------------------------------\n",
    "        # Get the records.\n",
    "        # Get max_records from the shard, or run continuously if you wish.\n",
    "        #-----------------------------------------------------------------\n",
    "        max_records = 100\n",
    "        record_count = 0\n",
    "\n",
    "        while record_count < max_records:\n",
    "            response = kinesis_client.get_records(\n",
    "                ShardIterator=shard_iterator,\n",
    "                Limit=10\n",
    "            )\n",
    "            shard_iterator = response['NextShardIterator']\n",
    "            records = response['Records']\n",
    "            record_count += len(records)\n",
    "            process_records(records)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't get records from stream %s.\", stream_name)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "459b46e5-84a6-4294-8432-6f6971e6d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d7e7daf-02ec-4f4e-9969-787a108b4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/17 17:06:04 WARN StreamingContext: spark.master should be set as local[n], n > 1 in local mode if you have receivers to get data, otherwise Spark jobs will not get resources to process the received data.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "# conf = SparkConf().setAppName(\"KinesisExample\")\n",
    "# sc = SparkContext(conf=conf)\n",
    "# ssc = StreamingContext(sc, 1)\n",
    "\n",
    "# conf = SparkConf().setAppName(\"app\").setMaster(\"local\").set('spark.jars', '/Users/programmer/Downloads/spark-sql-kinesis_2.11-1.1.3-spark_2.4.jar')\n",
    "# sc = SparkContext(conf=conf)\n",
    "ssc = StreamingContext(sc, 1)\n",
    "\n",
    "\n",
    "kinesis_stream_name = stream_name\n",
    "kinesis_endpoint_url = \"http://localhost:4566/000000000000/stream/dummy-queue\"\n",
    "aws_access_key_id = \"dummy\"\n",
    "aws_secret_key = \"dummy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "501be3b1-956d-4cb7-a43c-0128e70d7cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "  Spark Streaming's Kinesis libraries not found in class path. Try one of the following.\n",
      "\n",
      "  1. Include the Streaming's Kinesis library and its dependencies with in the\n",
      "     spark-submit command as\n",
      "\n",
      "     $ bin/spark-submit --packages org.apache.spark:spark-streaming-kinesis-asl:3.5.0 ...\n",
      "\n",
      "  2. Download the JAR of the artifact from Maven Central http://search.maven.org/,\n",
      "     Group Id = org.apache.spark, Artifact Id = spark-streaming-kinesis-asl-assembly, Version = 3.5.0.\n",
      "     Then, include the jar in the spark-submit command as\n",
      "\n",
      "     $ bin/spark-submit --jars <spark-streaming-kinesis-asl-assembly.jar> ...\n",
      "\n",
      "________________________________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mKinesisUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkinesisAppName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPythonKinesisExample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpointUrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkinesis_endpoint_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregionName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43map-south-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitialPositionInStream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mInitialPositionInStream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLATEST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpointInterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorageLevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mStorageLevel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMEMORY_AND_DISK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawsAccessKeyId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maws_access_key_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawsSecretKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maws_secret_key\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m stream\u001b[38;5;241m.\u001b[39mpprint()\n\u001b[1;32m     16\u001b[0m ssc\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aps/lib/python3.10/site-packages/pyspark/streaming/kinesis.py:178\u001b[0m, in \u001b[0;36mKinesisUtils.createStream\u001b[0;34m(ssc, kinesisAppName, streamName, endpointUrl, regionName, initialPositionInStream, checkpointInterval, metricsLevel, storageLevel, awsAccessKeyId, awsSecretKey, decoder, stsAssumeRoleArn, stsSessionName, stsExternalId)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     helper \u001b[38;5;241m=\u001b[39m \u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkinesis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKinesisUtilsPythonHelper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJavaPackage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not callable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "stream = KinesisUtils.createStream(\n",
    "    ssc, \n",
    "    kinesisAppName=\"PythonKinesisExample\", \n",
    "    streamName=stream_name,\n",
    "    endpointUrl=kinesis_endpoint_url, \n",
    "    regionName=\"ap-south-1\", \n",
    "    initialPositionInStream=InitialPositionInStream.LATEST, \n",
    "    checkpointInterval=5,\n",
    "    storageLevel = StorageLevel.MEMORY_AND_DISK,\n",
    "    awsAccessKeyId=aws_access_key_id,\n",
    "    awsSecretKey=aws_secret_key\n",
    ")\n",
    "\n",
    "stream.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c8b7e-f369-40aa-bd7d-6e53c19fba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53e519db-803a-4ae5-9892-c012f4fddff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ee9dad5-5019-4420-8363-e5607300ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.roncemer.spark/spark-sql-kinesis_2.13/1.2.2_spark-3.2 pyspark-shell'\n",
    "os.environ['JAVA_HOME'] = \"/Library/Java/JavaVirtualMachines/jdk-21.jdk/Contents/Home\"\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ed42192-40b6-4e66-8cd9-ede51b628748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b51f4c68-fab6-414d-ba05-d32b54941a49",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o98.load.\n: java.lang.NoClassDefFoundError: org/apache/spark/sql/sources/v2/ContinuousReadSupport\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:756)\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:473)\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:348)\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:370)\n\tat java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)\n\tat java.util.ServiceLoader$1.next(ServiceLoader.java:480)\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:46)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat scala.collection.TraversableLike.filterImpl(TraversableLike.scala:303)\n\tat scala.collection.TraversableLike.filterImpl$(TraversableLike.scala:297)\n\tat scala.collection.AbstractTraversable.filterImpl(Traversable.scala:108)\n\tat scala.collection.TraversableLike.filter(TraversableLike.scala:395)\n\tat scala.collection.TraversableLike.filter$(TraversableLike.scala:395)\n\tat scala.collection.AbstractTraversable.filter(Traversable.scala:108)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:629)\n\tat org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:158)\n\tat org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: org.apache.spark.sql.sources.v2.ContinuousReadSupport\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\t... 44 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create DataFrame representing the stream of input lines from connection to localhost:9999\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadStream\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msocket\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9999\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Split the lines into words\u001b[39;00m\n\u001b[1;32m     10\u001b[0m words \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     11\u001b[0m    explode(\n\u001b[1;32m     12\u001b[0m        split(lines\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m    )\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aps/lib/python3.10/site-packages/pyspark/sql/streaming/readwriter.py:304\u001b[0m, in \u001b[0;36mDataStreamReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(path))\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aps/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aps/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aps/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o98.load.\n: java.lang.NoClassDefFoundError: org/apache/spark/sql/sources/v2/ContinuousReadSupport\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:756)\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:473)\n\tat java.net.URLClassLoader.access$100(URLClassLoader.java:74)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:369)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:363)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:362)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:348)\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:370)\n\tat java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)\n\tat java.util.ServiceLoader$1.next(ServiceLoader.java:480)\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:46)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat scala.collection.TraversableLike.filterImpl(TraversableLike.scala:303)\n\tat scala.collection.TraversableLike.filterImpl$(TraversableLike.scala:297)\n\tat scala.collection.AbstractTraversable.filterImpl(Traversable.scala:108)\n\tat scala.collection.TraversableLike.filter(TraversableLike.scala:395)\n\tat scala.collection.TraversableLike.filter$(TraversableLike.scala:395)\n\tat scala.collection.AbstractTraversable.filter(Traversable.scala:108)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:629)\n\tat org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:158)\n\tat org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: org.apache.spark.sql.sources.v2.ContinuousReadSupport\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\t... 44 more\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame representing the stream of input lines from connection to localhost:9999\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9999) \\\n",
    "    .load()\n",
    "\n",
    "# Split the lines into words\n",
    "words = lines.select(\n",
    "   explode(\n",
    "       split(lines.value, \" \")\n",
    "   ).alias(\"word\")\n",
    ")\n",
    "\n",
    "# Generate running word count\n",
    "wordCounts = words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25a14b-c4e1-4336-b9a7-5dd3b9924b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = wordCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3a41d-ac7a-4be1-a639-63449a9c848b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
